# Xander Davies

<img src="https://user-images.githubusercontent.com/55059966/184758103-6358d0c3-1423-4c3c-b2b4-b28c9ea9cb44.jpeg" alt="xander" width="200"/>

Hi, I'm Xander. I'm going into my fourth year at Harvard, where I study computer science. I lead the [Harvard AI Safety Team](https://harvardaist.org), and currently do deep learning theory research with [David Krueger](https://www.davidscottkrueger.com/)'s lab at Cambridge University. I'm interested in making sure advanced AI is developed safely. I also enjoy writing, chess, listening to music, and [playing](https://drive.google.com/file/d/1a9ItWvJHRpqune1srF5lVXOg2osX_imA/view?usp=sharing) [piano](https://drive.google.com/file/d/1FPIZnW3uex4eCUomlKBqNMdyqf958JVi/view?usp=sharing). If you'd like to discuss any of this, feel free to email me at alexander_davies [at] college [dot] harvard [dot] edu.

## Publications

**Davies, X.**, Langosco, L., & Krueger, D. (2022). [Unifying Grokking and Double Descent](https://drive.google.com/file/d/1M0IBM0j8PbwwqQ_JNJqm5Mfms3ENOSqY/view?usp=sharing). *2022 NeurIPS ML Safety Workshop.*

Bricken, T., **Davies, X.**, Singh, D., Krotov, D., & Kreiman, G. (2022, November 15). [Sparse Distributed Memory is a Continual Learner](https://drive.google.com/file/d/1tJhRO6JfCo2yPatnYXweiGL7sQDYYLpE/view?usp=sharing). *In review, ICLR 2022.*


## Writing

[Update on Harvard AI Safety Team and MIT AI Alignment](https://www.lesswrong.com/posts/LShJtvwDf4AMo992L#)

[Toy Grokking with a Linear Model](writing/toy_grok/toy_grok.html)

[Gradient Descent's Implicit Bias on Separable Data](writing/implicit_bias_sgd/gd_imp_sep.html)

[Announcing the Harvard AI Safety Team](https://forum.effectivealtruism.org/posts/NvzeAtoynxGjDnWkp/announcing-the-harvard-ai-safety-team)
