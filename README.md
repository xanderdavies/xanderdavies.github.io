# Xander Davies

<img src="https://user-images.githubusercontent.com/55059966/205596332-86fcf764-2eb6-4933-8f1c-eee0fa26593b.jpeg" alt="xander" width="200"/>

Hi, I'm Xander. I'm going into my fourth year at Harvard, where I study computer science. I lead the [Harvard AI Safety Team](https://harvardaist.org), and previously co-led Redwood Research's [REMIX interpretability residency](https://www.redwoodresearch.org/remix). I've previously researched grokking and double descent with [David Krueger](https://www.davidscottkrueger.com/)'s lab at Cambridge University, and am now working on mechanistic interpretability with [David Bau](https://baulab.info/) at Northeastern University. I'm interested in making sure advanced AI is developed safely. I also enjoy writing, chess, listening to music, [and](https://drive.google.com/file/d/1a9ItWvJHRpqune1srF5lVXOg2osX_imA/view?usp=sharing) [playing](https://drive.google.com/file/d/1FPIZnW3uex4eCUomlKBqNMdyqf958JVi/view?usp=sharing) [piano](https://drive.google.com/file/d/1VRXvsDpkhYVeTdmUOT2_Lwfewkui3c_0/view?usp=sharing)[.](https://drive.google.com/file/d/1_RGtxt5Vn9Ob8-DvfG3AxNICyObTnwqf/view?usp=sharing) If you'd like to discuss any of this, feel free to email me at alexander_davies [at] college [dot] harvard [dot] edu.

## Publications

**Davies, X.\***, Langosco, L.\*, & Krueger, D. (2022). [Unifying Grokking and Double Descent](https://arxiv.org/abs/2303.06173). In *2022 NeurIPS ML Safety Workshop.*

Bricken, T., **Davies, X.**, Singh, D., Krotov, D., & Kreiman, G. (2023). [Sparse Distributed Memory is a Continual Learner](https://arxiv.org/abs/2303.11934). In *ICLR 2023.*


## Writing & Press

[Harvard Crimson: Undergraduates Ramp Up Harvard AI Safety Team Amid Concerns Over Increasingly Powerful AI Models](https://www.thecrimson.com/article/2023/3/22/haist-ai-safety/)

[Update on Harvard AI Safety Team and MIT AI Alignment](https://www.lesswrong.com/posts/LShJtvwDf4AMo992L#)

[Toy Grokking with a Linear Model](writing/toy_grok/toy_grok.html)

[Gradient Descent's Implicit Bias on Separable Data](writing/implicit_bias_sgd/gd_imp_sep.html)

[Announcing the Harvard AI Safety Team](https://forum.effectivealtruism.org/posts/NvzeAtoynxGjDnWkp/announcing-the-harvard-ai-safety-team)
